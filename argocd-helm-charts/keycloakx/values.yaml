keycloakx:
  command:
    - "/opt/keycloak/bin/kc.sh"
    - "--verbose"
    - "start"
    - "--http-enabled=true"
    - "--http-port=8080"
    - "--hostname-strict=false"
    - "--spi-events-listener-jboss-logging-success-level=info"
    - "--spi-events-listener-jboss-logging-error-level=warn"
  proxy:
    mode: xforwarded
  database:
    vendor: postgres
    hostname: keycloak-pgsql-rw
    port: 5432
    database: keycloak
  extraEnv: |
    - name: KC_DB_USERNAME
      valueFrom:
        secretKeyRef:
          name: keycloak-pgsql-app
          key: username
    - name: KC_DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: keycloak-pgsql-app
          key: password
    - name: KEYCLOAK_ADMIN
      value: admin
    - name: KEYCLOAK_ADMIN_PASSWORD
      valueFrom:
        secretKeyRef:
          name: keycloak-admin
          key: KEYCLOAK_PASSWORD
    - name: JAVA_OPTS_APPEND
      value: >-
        -Djgroups.dns.query={{ include "keycloak.fullname" . }}-headless

  resources:
    requests:
      cpu: 500m
      memory: 300Mi
    limits:
      memory: 1000Mi

  dbchecker:
    enabled: true

postgresql:
  # CloudNativePG (CNPG) currently doesn't support in-place recovery of a cluster.
  #
  # This means : suppose a cluster initially was using
  # s3://blackwoodseven-cnpg-poc/keycloakx/keycloak-pgsql to store its backups. While recovering
  # the cluster, you'll recover from that path, but you cannot write any further backups of the
  # recovered cluster to that path.
  #
  # That's why, to keep the cluster name same, we initially change the path to
  # s3://blackwoodseven-cnpg-poc/keycloakx/keycloak-pgsql/revision-0. And everytime you recover
  # the cluster, you increment that revision number, and the S3 path will change.
  revision: 0

  instances: 1

  resources:
    requests:
      cpu: 100m
      memory: 500Mi
    limits:
      memory: 800Mi

  size: 4Gi
  storageClass: default

  # The following labels will be applied to the Cluster resource.
  #
  # Note that, if you want any of these labels to be propagated to the corresponding pods, you need
  # to include them in cloudnative-pg.config.data.INHERITED_ANNOTATIONS in the cnpg-operator's Helm
  # chart.
  labels:
    # Recovery of a PostgreSQL cluster currently requires manual interventation, and can't be done
    # automatically. For e.g., when using CloudNativePG, we need to increment the revision number
    # (should be done by KubeAid CLI, if you're using that).
    #
    # This is why, we would like to disable Velero from backing up the Cluster / postgresql
    # resources, so when recovering, those resources don't get created automatically.
    velero.io/exclude-from-backup: "true"

  recover:
    enabled: false
    revision: 0

  backups:
    enabled: true

    schedule: "0 0 0 * * *"
    retentionPolicy: 30d

    # Currently, we support : AWS and Azure.
    provider: aws

    aws:
      # Whether to enable Kube2IAM integration, instead of providing static AWS credentials
      # from a Kubernetes Secret.
      enableKube2IAMIntegration: true

blackbox:
  probe: true
